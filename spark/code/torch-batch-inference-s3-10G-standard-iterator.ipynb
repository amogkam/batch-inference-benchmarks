{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "701d2809-daab-4de6-979d-ff8c6aab47cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[1]: True"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "torch.__version__\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59841386-1fb4-4a0c-afbe-922f8f8049d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor memory:  148728m\n"
     ]
    }
   ],
   "source": [
    "#print(\"Profiling enabled: \", spark.conf.get(\"spark.python.profile\"))\n",
    "print(\"Executor memory: \", spark.conf.get(\"spark.executor.memory\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d5cb47e-49c5-4904-9df3-538972665541",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4832578-6320-43f6-a462-bd8eb1ae454b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Enable Arrow support.\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6229f4e-80ba-40ea-bac7-9d07bc2b84fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a401f46c6c434755b5c19acf7a119c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and broadcast model state. Equivalent to AIR Checkpoint\n",
    "model_state = resnet50(weights=ResNet50_Weights.DEFAULT).state_dict()\n",
    "# sc is already initialized by Databricks. Broadcast the model state to all executors.\n",
    "bc_model_state = sc.broadcast(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "525bb7ea-f7b3-44ff-a013-3d8d9fc82135",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_data = spark.read.format(\"parquet\").load(\"s3://air-example-data-2/10G-image-data-synthetic-raw-parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef059a6f-8c22-44ef-960c-518956975eb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from typing import Iterator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Read documentation here: https://spark.apache.org/docs/3.0.1/sql-pyspark-pandas-with-arrow.html\n",
    "\n",
    "@pandas_udf(ArrayType(FloatType()))\n",
    "def preprocess(image_iter: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    preprocess = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    for image in image_iter:\n",
    "        print(f\"number of images: {len(image)}\")\n",
    "        # Spark has no tensor support, so it flattens the image tensor to a single array during read.\n",
    "        # Each image is represented as a flattened numpy array.\n",
    "        # We have to reshape back to the original number of dimensions.\n",
    "        # Need to convert to float dtype otherwise torchvision transforms will complain. The data is read as short (int16) by default\n",
    "        batch_dim = len(image)\n",
    "        numpy_batch = np.stack(image.values)\n",
    "        reshaped_images = numpy_batch.reshape(batch_dim, 256, 256, 3).astype(np.float)\n",
    "        \n",
    "        torch_tensor = torch.Tensor(reshaped_images.transpose(0, 3, 1, 2))\n",
    "        preprocessed_images = preprocess(torch_tensor).numpy()\n",
    "        # Arrow only works with single dimension numpy arrays, so need to flatten the array before outputting it\n",
    "        preprocessed_images = [image.flatten() for image in preprocessed_images]\n",
    "        yield pd.Series(preprocessed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9af2d6fc-4fb8-4983-aca3-672381e96310",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "preprocessed_data = input_data.select(preprocess(col(\"image\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "370ef5d5-55a1-4821-b428-414a62a36620",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1000 is the largest batch size that can fit on GPU. Limit batch size to 1000 to avoid CUDA OOM.\n",
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48c15069-1c2f-47c3-9b1c-6fe0eb5641e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "\n",
    "@pandas_udf(ArrayType(FloatType()))\n",
    "def predict(preprocessed_images_iter: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    with torch.inference_mode():\n",
    "        model = resnet50()\n",
    "        model.load_state_dict(bc_model_state.value)\n",
    "        model = model.to(torch.device(\"cuda\")) # Move model to GPU\n",
    "        model.eval()\n",
    "        \n",
    "        for preprocessed_images in preprocessed_images_iter:\n",
    "            batch = preprocessed_images\n",
    "            batch_dim = len(batch)\n",
    "            numpy_batch = np.stack(batch.values)\n",
    "            # Spark has no tensor support, so it flattens the image tensor to a single array during read.\n",
    "            # Each image is represented as a flattened numpy array.\n",
    "            # We have to reshape back to the original number of dimensions.\n",
    "            reshaped_images = numpy_batch.reshape(batch_dim, 3, 224, 224)\n",
    "            gpu_batch = torch.Tensor(reshaped_images).to(torch.device(\"cuda\"))\n",
    "            predictions = list(model(gpu_batch).cpu().numpy())\n",
    "            assert len(predictions) == batch_dim\n",
    "            \n",
    "            yield pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d30eb582-afe4-433c-9fee-9dc5c6f3cf86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions = preprocessed_data.select(predict(col(\"preprocess(image)\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "505599b5-fdd0-4f55-bb9d-f17898858f47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction took: 143.19921851158142 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "predictions.write.mode(\"overwrite\").format(\"noop\").save()\n",
    "end_time = time.time()\n",
    "print(f\"Prediction took: {end_time-start_time} seconds\")\n",
    "\n",
    "assert preprocessed_data.count() == 16232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8da01873-5803-4813-b561-0fb6819f9dc8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "torch-batch-inference-s3-10G-standard-iterator",
   "notebookOrigID": 4465860287893945,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
